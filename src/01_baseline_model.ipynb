{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b2aab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [SFO í”„ë¡œì íŠ¸ [2/2] - ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì‹œì‘] ---\n",
      "\n",
      "--- [1ë‹¨ê³„: ì „ì²˜ë¦¬ëœ ë°ì´í„° '../data/baseline_processed.csv' ë¡œë“œ ì‹œì‘] ---\n",
      "âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ ì™„ë£Œ (shape: (10624, 19))\n",
      "   'Date' ì»¬ëŸ¼ íƒ€ì…: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## ğŸš€ SFO í”„ë¡œì íŠ¸- ëª¨ë¸ í•™ìŠµ ë° ì €ì¥\n",
    "#\n",
    "# - **ì „ì²˜ë¦¬ ì™„ë£Œëœ CSV íŒŒì¼ ë¡œë“œ**\n",
    "# - Train/Validation ë°ì´í„° ë¶„í•  (ì‹œê°„ ê¸°ë°˜)\n",
    "# - **LightGBM ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í•™ìŠµ**\n",
    "# - **ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ë° MAE, R2 ì¶œë ¥**\n",
    "# - **í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ë¡œ ì €ì¥**\n",
    "#\n",
    "# **[ì‹œì‘ ì „ ì¤€ë¹„ì‚¬í•­]**\n",
    "# 1. `00_baseline_processed` ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ `baseline_processed.csv` íŒŒì¼ì´ ìƒì„±ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# 2. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜: `pip install pandas numpy lightgbm scikit-learn joblib`\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import joblib # ëª¨ë¸ ì €ì¥ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "# --- 0. ì„¤ì • ë° íŒŒì¼ ê²½ë¡œ ì •ì˜ ---\n",
    "input_processed_csv_file = '../data/baseline_processed.csv' \n",
    "model_save_path = '../data/baseline_lightgbm_model.pkl' # í•™ìŠµëœ ëª¨ë¸ ì €ì¥ ê²½ë¡œ\n",
    "\n",
    "target_column = 'Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰'\n",
    "\n",
    "print(\"--- [SFO í”„ë¡œì íŠ¸ [2/2] - ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì‹œì‘] ---\")\n",
    "\n",
    "\n",
    "# --- 1ë‹¨ê³„: ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ ---\n",
    "print(f\"\\n--- [1ë‹¨ê³„: ì „ì²˜ë¦¬ëœ ë°ì´í„° '{input_processed_csv_file}' ë¡œë“œ ì‹œì‘] ---\")\n",
    "df_manual_features_encoded = None\n",
    "try:\n",
    "    if not os.path.exists(input_processed_csv_file):\n",
    "        raise FileNotFoundError(f\"ğŸš¨ ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ '{input_processed_csv_file}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. \\n   [íŒŒì¼ 1: 01_preprocess_and_save.py] ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "    \n",
    "    df_manual_features_encoded = pd.read_csv(input_processed_csv_file)\n",
    "    \n",
    "    # !! ë§¤ìš° ì¤‘ìš” !!\n",
    "    # CSVë¡œ ì €ì¥í•˜ë©´ì„œ ë¬¸ìì—´ì´ ëœ 'Date' ì»¬ëŸ¼ì„ ë‹¤ì‹œ datetime ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    # ì‹œê°„ ê¸°ë°˜ ë°ì´í„° ë¶„í• (splitting)ì„ ìœ„í•´ í•„ìˆ˜ì…ë‹ˆë‹¤.\n",
    "    df_manual_features_encoded['Date'] = pd.to_datetime(df_manual_features_encoded['Date'])\n",
    "    \n",
    "    print(f\"âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ ì™„ë£Œ (shape: {df_manual_features_encoded.shape})\")\n",
    "    print(f\"   'Date' ì»¬ëŸ¼ íƒ€ì…: {df_manual_features_encoded['Date'].dtype}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ğŸš¨ {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ 1ë‹¨ê³„ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    df_manual_features_encoded = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c8c50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [2ë‹¨ê³„: LightGBM ìµœì¢… ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œì‘] ---\n",
      "2.1. ë°ì´í„° ë¶„í•  ì™„ë£Œ: Train_X: (8499, 16), Train_y: (8499,), Val_X: (2125, 16), Val_y: (2125,)\n",
      "   - ìµœì¢… ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©ë  í”¼ì²˜ ê°œìˆ˜: 16ê°œ\n",
      "\n",
      "2.2. LightGBM ìµœì¢… ëª¨ë¸ í•™ìŠµ ì‹œì‘ (Optuna ìµœì  íŒŒë¼ë¯¸í„°)...\n",
      "\n",
      "âœ… LightGBM ìµœì¢… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "   - ìµœì¢… ëª¨ë¸ ê²€ì¦ MAE: 16.75\n",
      "   - ìµœì¢… ëª¨ë¸ ê²€ì¦ R2: 0.928\n",
      "âœ… í•™ìŠµëœ ìµœì¢… ëª¨ë¸ì´ '../data/baseline_lightgbm_model.pkl'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "--- [SFO í”„ë¡œì íŠ¸ [2/2] - ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì¢…ë£Œ] ---\n"
     ]
    }
   ],
   "source": [
    "# --- 2ë‹¨ê³„: LightGBM ìµœì¢… ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ---\n",
    "final_model = None\n",
    "\n",
    "if df_manual_features_encoded is not None and not df_manual_features_encoded.empty:\n",
    "    print(\"\\n--- [2ë‹¨ê³„: LightGBM ìµœì¢… ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œì‘] ---\")\n",
    "    try:\n",
    "        # 2.1. ë°ì´í„° ë¶„í•  (Train/Validation - ì‹œê°„ ê¸°ë°˜)\n",
    "        # 'Date' ì»¬ëŸ¼ì´ datetime íƒ€ì…ì´ì–´ì•¼ sort_valuesê°€ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•©ë‹ˆë‹¤.\n",
    "        df_manual_features_encoded = df_manual_features_encoded.sort_values(by='Date')\n",
    "        \n",
    "        train_ratio = 0.8\n",
    "        split_idx = int(len(df_manual_features_encoded) * train_ratio)\n",
    "\n",
    "        train_df = df_manual_features_encoded.iloc[:split_idx]\n",
    "        val_df = df_manual_features_encoded.iloc[split_idx:]\n",
    "\n",
    "        # â–¼â–¼â–¼â–¼â–¼ [ìˆ˜ì •ëœ ë¶€ë¶„] â–¼â–¼â–¼â–¼â–¼\n",
    "        # 'object' íƒ€ì…ì˜ ì›ë³¸ Product_Number ì»¬ëŸ¼ì„ í”¼ì²˜ì—ì„œ ì œì™¸ì‹œí‚µë‹ˆë‹¤.\n",
    "        features_to_exclude_from_X = ['Date', target_column, 'Product_Number']\n",
    "        # â–²â–²â–²â–²â–² [ìˆ˜ì •ëœ ë¶€ë¶„] â–²â–²â–²â–²â–²\n",
    "\n",
    "        X_train = train_df.drop(columns=features_to_exclude_from_X)\n",
    "        y_train = train_df[target_column]\n",
    "        X_val = val_df.drop(columns=features_to_exclude_from_X)\n",
    "        y_val = val_df[target_column]\n",
    "        \n",
    "        # (ì°¸ê³ ) ë§Œì•½ 'DayOfWeek' ì›ë³¸ ì»¬ëŸ¼ë„ ë‚¨ì•„ìˆë‹¤ë©´ ìœ„ ë¦¬ìŠ¤íŠ¸ì— 'DayOfWeek'ë„ ì¶”ê°€í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        # features_to_exclude_from_X = ['Date', target_column, 'Product_Number', 'DayOfWeek']\n",
    "\n",
    "        print(f\"2.1. ë°ì´í„° ë¶„í•  ì™„ë£Œ: Train_X: {X_train.shape}, Train_y: {y_train.shape}, Val_X: {X_val.shape}, Val_y: {y_val.shape}\")\n",
    "        print(f\"   - ìµœì¢… ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©ë  í”¼ì²˜ ê°œìˆ˜: {X_train.shape[1]}ê°œ\")\n",
    "\n",
    "\n",
    "        # 2.2. LightGBM ìµœì¢… ëª¨ë¸ í•™ìŠµ (Optuna ìµœì  íŒŒë¼ë¯¸í„° ì ìš©)\n",
    "        print(\"\\n2.2. LightGBM ìµœì¢… ëª¨ë¸ í•™ìŠµ ì‹œì‘ (Optuna ìµœì  íŒŒë¼ë¯¸í„°)...\")\n",
    "        # --- ì—¬ê¸°ì— Optunaë¡œ ì°¾ì€ ìµœì¢… ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì…ë ¥í•˜ì„¸ìš”! ---\n",
    "        # ì˜ˆì‹œ íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤. ë°œí‘œì˜ MAE 11.92, R2 0.957ì„ ë‹¬ì„±í•œ íŒŒë¼ë¯¸í„°ë¡œ êµì²´í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "        lgbm_final_params = {\n",
    "            'objective': 'regression_l1', # MAEë¥¼ ì§ì ‘ ìµœì í™”\n",
    "            'metric': 'mae',\n",
    "            'n_estimators': 2000,         # ì¶©ë¶„íˆ í° ê°’ ì„¤ì • í›„ early stopping\n",
    "            'learning_rate': 0.01,\n",
    "            'num_leaves':32,\n",
    "            'max_depth': 7,\n",
    "            'min_child_samples': 15,\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'verbose': -1,                # í•™ìŠµ ê³¼ì • ë©”ì‹œì§€ ì¶œë ¥ ì–µì œ\n",
    "            'boosting_type': 'gbdt',\n",
    "        }\n",
    "\n",
    "        final_model = lgb.LGBMRegressor(**lgbm_final_params)\n",
    "        final_model.fit(X_train, y_train,\n",
    "                        eval_set=[(X_val, y_val)],\n",
    "                        eval_metric='mae',\n",
    "                        callbacks=[lgb.early_stopping(100, verbose=False)]) # 100íšŒ ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ\n",
    "\n",
    "        print(\"\\nâœ… LightGBM ìµœì¢… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "\n",
    "        # 2.3. ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ë° ì„±ëŠ¥ í‰ê°€\n",
    "        val_preds = final_model.predict(X_val)\n",
    "        final_mae = mean_absolute_error(y_val, val_preds)\n",
    "        final_r2 = r2_score(y_val, val_preds)\n",
    "        print(f\"   - ìµœì¢… ëª¨ë¸ ê²€ì¦ MAE: {final_mae:.2f}\")\n",
    "        print(f\"   - ìµœì¢… ëª¨ë¸ ê²€ì¦ R2: {final_r2:.3f}\")\n",
    "\n",
    "        # 2.4. í•™ìŠµëœ ëª¨ë¸ ì €ì¥\n",
    "        try:\n",
    "            joblib.dump(final_model, model_save_path)\n",
    "            print(f\"âœ… í•™ìŠµëœ ìµœì¢… ëª¨ë¸ì´ '{model_save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        except Exception as e:\n",
    "            print(f\"ğŸš¨ ëª¨ë¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "        # 2.5. (ì„ íƒ ì‚¬í•­) ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì˜ˆì‹œ\n",
    "        # loaded_model = joblib.load(model_save_path)\n",
    "        # print(f\"âœ… ëª¨ë¸ '{model_save_path}' ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ.\")\n",
    "        # loaded_preds = loaded_model.predict(X_val)\n",
    "        # print(f\"   - ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ë¡œ ì˜ˆì¸¡í•œ MAE: {mean_absolute_error(y_val, loaded_preds):.2f}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ 2ë‹¨ê³„ LightGBM ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "else:\n",
    "    print(\"ğŸš¨ 1ë‹¨ê³„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ë¡œ 2ë‹¨ê³„ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\n--- [SFO í”„ë¡œì íŠ¸ [2/2] - ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì¢…ë£Œ] ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
