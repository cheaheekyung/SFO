{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2aab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [SFO 프로젝트 [2/2] - 모델 학습 및 저장 시작] ---\n",
      "\n",
      "--- [1단계: 전처리된 데이터 'C:/portfolio/SFO/notebooks/EDA/baseline_processed.csv' 로드 시작] ---\n",
      "✅ 전처리된 데이터 로드 완료 (shape: (10624, 19))\n",
      "   'Date' 컬럼 타입: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 🚀 SFO 프로젝트 [2/2] - 모델 학습 및 저장\n",
    "#\n",
    "# - **전처리 완료된 CSV 파일 로드**\n",
    "# - Train/Validation 데이터 분할 (시간 기반)\n",
    "# - **LightGBM 최종 모델 학습** (Optuna 최적 파라미터 적용)\n",
    "# - **검증 데이터에 대한 예측 및 MAE, R2 출력**\n",
    "# - **학습된 모델 파일로 저장**\n",
    "#\n",
    "# **[시작 전 준비사항]**\n",
    "# 1. `00_baseline_processed.ipynb` 스크립트를 먼저 실행하여 `df_manual_features_encoded.csv` 파일이 생성되어 있어야 합니다.\n",
    "# 2. 필요한 라이브러리 설치: `pip install pandas numpy lightgbm scikit-learn joblib`\n",
    "#\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import joblib # 모델 저장을 위한 라이브러리\n",
    "\n",
    "# --- 0. 설정 및 파일 경로 정의 ---\n",
    "input_processed_csv_file = 'baseline_processed.csv' # 중요!! 경로 설정해줘야함!!\n",
    "model_save_path = '../../data/baseline_lightgbm_model.pkl' # 학습된 모델 저장 경로\n",
    "\n",
    "target_column = 'T일 예정 수주량'\n",
    "\n",
    "print(\"--- [SFO 프로젝트 [2/2] - 모델 학습 및 저장 시작] ---\")\n",
    "\n",
    "\n",
    "# --- 1단계: 전처리된 데이터 로드 ---\n",
    "print(f\"\\n--- [1단계: 전처리된 데이터 '{input_processed_csv_file}' 로드 시작] ---\")\n",
    "df_manual_features_encoded = None\n",
    "try:\n",
    "    if not os.path.exists(input_processed_csv_file):\n",
    "        raise FileNotFoundError(f\"🚨 오류: 입력 파일 '{input_processed_csv_file}'을(를) 찾을 수 없습니다. \\n   [파일 1: 01_preprocess_and_save.py] 스크립트를 먼저 실행했는지 확인하세요.\")\n",
    "    \n",
    "    df_manual_features_encoded = pd.read_csv(input_processed_csv_file)\n",
    "    \n",
    "    # !! 매우 중요 !!\n",
    "    # CSV로 저장하면서 문자열이 된 'Date' 컬럼을 다시 datetime 객체로 변환합니다.\n",
    "    # 시간 기반 데이터 분할(splitting)을 위해 필수입니다.\n",
    "    df_manual_features_encoded['Date'] = pd.to_datetime(df_manual_features_encoded['Date'])\n",
    "    \n",
    "    print(f\"✅ 전처리된 데이터 로드 완료 (shape: {df_manual_features_encoded.shape})\")\n",
    "    print(f\"   'Date' 컬럼 타입: {df_manual_features_encoded['Date'].dtype}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"🚨 {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"🚨 1단계 데이터 로드 중 오류: {e}\")\n",
    "    df_manual_features_encoded = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c8c50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [2단계: LightGBM 최종 모델 학습 및 예측 시작] ---\n",
      "2.1. 데이터 분할 완료: Train_X: (8499, 16), Train_y: (8499,), Val_X: (2125, 16), Val_y: (2125,)\n",
      "   - 최종 모델 학습에 사용될 피처 개수: 16개\n",
      "\n",
      "2.2. LightGBM 최종 모델 학습 시작 (Optuna 최적 파라미터)...\n",
      "\n",
      "✅ LightGBM 최종 모델 학습 완료!\n",
      "   - 최종 모델 검증 MAE: 15.19\n",
      "   - 최종 모델 검증 R2: 0.940\n",
      "✅ 학습된 최종 모델이 '../../data/baseline_lightgbm_model.pkl'에 저장되었습니다.\n",
      "\n",
      "--- [SFO 프로젝트 [2/2] - 모델 학습 및 저장 종료] ---\n"
     ]
    }
   ],
   "source": [
    "# --- 2단계: LightGBM 최종 모델 학습 및 예측 ---\n",
    "final_model = None\n",
    "\n",
    "if df_manual_features_encoded is not None and not df_manual_features_encoded.empty:\n",
    "    print(\"\\n--- [2단계: LightGBM 최종 모델 학습 및 예측 시작] ---\")\n",
    "    try:\n",
    "        # 2.1. 데이터 분할 (Train/Validation - 시간 기반)\n",
    "        # 'Date' 컬럼이 datetime 타입이어야 sort_values가 올바르게 작동합니다.\n",
    "        df_manual_features_encoded = df_manual_features_encoded.sort_values(by='Date')\n",
    "        \n",
    "        train_ratio = 0.8\n",
    "        split_idx = int(len(df_manual_features_encoded) * train_ratio)\n",
    "\n",
    "        train_df = df_manual_features_encoded.iloc[:split_idx]\n",
    "        val_df = df_manual_features_encoded.iloc[split_idx:]\n",
    "\n",
    "        # ▼▼▼▼▼ [수정된 부분] ▼▼▼▼▼\n",
    "        # 'object' 타입의 원본 Product_Number 컬럼을 피처에서 제외시킵니다.\n",
    "        features_to_exclude_from_X = ['Date', target_column, 'Product_Number']\n",
    "        # ▲▲▲▲▲ [수정된 부분] ▲▲▲▲▲\n",
    "\n",
    "        X_train = train_df.drop(columns=features_to_exclude_from_X)\n",
    "        y_train = train_df[target_column]\n",
    "        X_val = val_df.drop(columns=features_to_exclude_from_X)\n",
    "        y_val = val_df[target_column]\n",
    "        \n",
    "        # (참고) 만약 'DayOfWeek' 원본 컬럼도 남아있다면 위 리스트에 'DayOfWeek'도 추가해야 할 수 있습니다.\n",
    "        # features_to_exclude_from_X = ['Date', target_column, 'Product_Number', 'DayOfWeek']\n",
    "\n",
    "        print(f\"2.1. 데이터 분할 완료: Train_X: {X_train.shape}, Train_y: {y_train.shape}, Val_X: {X_val.shape}, Val_y: {y_val.shape}\")\n",
    "        print(f\"   - 최종 모델 학습에 사용될 피처 개수: {X_train.shape[1]}개\")\n",
    "\n",
    "\n",
    "        # 2.2. LightGBM 최종 모델 학습 (Optuna 최적 파라미터 적용)\n",
    "        print(\"\\n2.2. LightGBM 최종 모델 학습 시작 (Optuna 최적 파라미터)...\")\n",
    "        # --- 여기에 Optuna로 찾은 최종 최적 파라미터를 입력하세요! ---\n",
    "        # 예시 파라미터입니다. 발표의 MAE 11.92, R2 0.957을 달성한 파라미터로 교체해야 합니다.\n",
    "        lgbm_final_params = {\n",
    "            'objective': 'regression_l1', # MAE를 직접 최적화\n",
    "            'metric': 'mae',\n",
    "            'n_estimators': 2000,         # 충분히 큰 값 설정 후 early stopping\n",
    "            'learning_rate': 0.01,\n",
    "            'num_leaves': 64,\n",
    "            'max_depth': 8,\n",
    "            'min_child_samples': 15,\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'verbose': -1,                # 학습 과정 메시지 출력 억제\n",
    "            'boosting_type': 'gbdt',\n",
    "        }\n",
    "\n",
    "        final_model = lgb.LGBMRegressor(**lgbm_final_params)\n",
    "        final_model.fit(X_train, y_train,\n",
    "                        eval_set=[(X_val, y_val)],\n",
    "                        eval_metric='mae',\n",
    "                        callbacks=[lgb.early_stopping(100, verbose=False)]) # 100회 동안 개선 없으면 조기 종료\n",
    "\n",
    "        print(\"\\n✅ LightGBM 최종 모델 학습 완료!\")\n",
    "\n",
    "        # 2.3. 검증 데이터에 대한 예측 및 성능 평가\n",
    "        val_preds = final_model.predict(X_val)\n",
    "        final_mae = mean_absolute_error(y_val, val_preds)\n",
    "        final_r2 = r2_score(y_val, val_preds)\n",
    "        print(f\"   - 최종 모델 검증 MAE: {final_mae:.2f}\")\n",
    "        print(f\"   - 최종 모델 검증 R2: {final_r2:.3f}\")\n",
    "\n",
    "        # 2.4. 학습된 모델 저장\n",
    "        try:\n",
    "            joblib.dump(final_model, model_save_path)\n",
    "            print(f\"✅ 학습된 최종 모델이 '{model_save_path}'에 저장되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"🚨 모델 저장 중 오류 발생: {e}\")\n",
    "\n",
    "        # 2.5. (선택 사항) 저장된 모델 불러오기 예시\n",
    "        # loaded_model = joblib.load(model_save_path)\n",
    "        # print(f\"✅ 모델 '{model_save_path}' 불러오기 완료.\")\n",
    "        # loaded_preds = loaded_model.predict(X_val)\n",
    "        # print(f\"   - 불러온 모델로 예측한 MAE: {mean_absolute_error(y_val, loaded_preds):.2f}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 2단계 LightGBM 모델 학습 및 예측 중 오류 발생: {e}\")\n",
    "else:\n",
    "    print(\"🚨 1단계 데이터 로드 실패로 2단계 모델 학습 및 예측을 시작할 수 없습니다.\")\n",
    "\n",
    "print(\"\\n--- [SFO 프로젝트 [2/2] - 모델 학습 및 저장 종료] ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SFO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
