{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49542c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## ğŸš€ SFO í”„ë¡œì íŠ¸ ë°ì´í„° ê³µí†µ ì „ì²˜ë¦¬ \n",
    "#\n",
    "# - ì›ë³¸ CSV íŒŒì¼ ë¡œë“œë¶€í„° `df_clean` ìƒì„±ê¹Œì§€ì˜ ê³µí†µ ì „ì²˜ë¦¬\n",
    "# - ìƒì„±ëœ df_cleanì„ csvë¡œ ì €ì¥\n",
    "#\n",
    "# [ì‹œì‘ ì „ ì¤€ë¹„ì‚¬í•­]\n",
    "# 1. `ì‚¬ì¶œì„±í˜•.csv` íŒŒì¼ ê²½ë¡œ í™•ì¸ (input_csv_file)\n",
    "# 2. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜: `pip install pandas numpy scikit-learn ipykernel `\n",
    "# \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84241c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ ë° ê³µí†µ ì „ì²˜ë¦¬ ì‹œì‘] ---\n",
      "1.1. ì›ë³¸ CSV íŒŒì¼ ë¡œë“œ ì™„ë£Œ (shape: (34617, 20))\n",
      "1.2. 'DoW' ì»¬ëŸ¼ ì œê±° ì™„ë£Œ.\n",
      "1.3. 'DateTime' ì»¬ëŸ¼ ì œê±° ì™„ë£Œ.\n",
      "1.4. ë°ì´í„° ì •ë ¬ ì™„ë£Œ (Product_Number, Date, Time).\n",
      "1.5. Product_Number-Date ì¤‘ë³µ ì œê±° ì™„ë£Œ (shape: (10624, 20)).\n",
      "1.6 'Humidity' ì´ìƒì¹˜ â†’ ì¤‘ì•™ê°’(28.03)ìœ¼ë¡œ ëŒ€ì²´ ì™„ë£Œ (shape: (10624, 20))\n",
      "1.7 ì‹œê³„ì—´ ì¬ë°°ì—´ (T+N â†’ T-N í˜•íƒœë¡œ ì •ë ¬)\n",
      "1ë‹¨ê³„ ê³µí†µ ì „ì²˜ë¦¬ ì™„ë£Œ! (df_clean shape: (10624, 19))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 0. ì„¤ì • ë° íŒŒì¼ ê²½ë¡œ ì •ì˜ ---\n",
    "input_csv_file = 'ì‚¬ì¶œì„±í˜•.csv'  \n",
    "output_final_csv_file = 'data/baseline_processed.csv' # ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥\n",
    "\n",
    "target_column = 'Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰'\n",
    "\n",
    "\n",
    "# --- 1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ ë° ê³µí†µ ì „ì²˜ë¦¬ (df_clean ìƒì„±) ---\n",
    "print(\"\\n--- [1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ ë° ê³µí†µ ì „ì²˜ë¦¬ ì‹œì‘] ---\")\n",
    "df_clean = None\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(input_csv_file):\n",
    "        raise FileNotFoundError(f\"ğŸš¨ ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ '{input_csv_file}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "    df_raw = pd.read_csv(input_csv_file)\n",
    "    print(f\"1.1. ì›ë³¸ CSV íŒŒì¼ ë¡œë“œ ì™„ë£Œ (shape: {df_raw.shape})\")\n",
    "\n",
    "    datetime_series = pd.to_datetime(df_raw['DateTime'], format='mixed', errors='coerce')\n",
    "    df_raw['Date'] = datetime_series.dt.date\n",
    "    df_raw['Time'] = datetime_series.dt.time\n",
    "\n",
    "    # ë‹¤ìŒ cellì—ì„œ ìˆ«ìí™”í•´ì„œ ìƒˆë¡œ ë§Œë“¦\n",
    "    if 'DoW' in df_raw.columns:\n",
    "        df_raw = df_raw.drop('DoW', axis=1)\n",
    "        print(\"1.2. 'DoW' ì»¬ëŸ¼ ì œê±° ì™„ë£Œ.\")\n",
    "    \n",
    "\n",
    "    if 'DateTime' in df_raw.columns:\n",
    "        df_raw.drop(['DateTime'], axis=1, inplace=True)\n",
    "        print(\"1.3. 'DateTime' ì»¬ëŸ¼ ì œê±° ì™„ë£Œ.\")\n",
    "\n",
    "    # 'Product_Number', 'Date', 'Time', 'Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰'ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "    df_raw.sort_values(by=['Product_Number', 'Date', 'Time', 'Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰'], inplace=True)\n",
    "    print(\"1.4. ë°ì´í„° ì •ë ¬ ì™„ë£Œ (Product_Number, Date, Time).\")\n",
    "\n",
    "    # ë§ˆì§€ë§‰ ê°’ ë‚¨ê¸°ê³  ì œê±°\n",
    "    data_df = df_raw.drop_duplicates(['Product_Number', 'Date'], keep='last').reset_index(drop=True)\n",
    "    print(f\"1.5. Product_Number-Date ì¤‘ë³µ ì œê±° ì™„ë£Œ (shape: {data_df.shape}).\")\n",
    "\n",
    "    # ìŠµë„ ì´ìƒì¹˜ ì²˜ë¦¬(ì´ìƒì¹˜-> ì •ìƒêµ¬ê°„ì˜ ì¤‘ì•™ê°’)\n",
    "    col_humidity = 'Humidity'\n",
    "\n",
    "    Q1_h = data_df[col_humidity].quantile(0.25)\n",
    "    Q3_h = data_df[col_humidity].quantile(0.75)\n",
    "    IQR_h = Q3_h - Q1_h\n",
    "    lower_bound_h = Q1_h - 1.5 * IQR_h\n",
    "    upper_bound_h = Q3_h + 1.5 * IQR_h\n",
    "\n",
    "    non_outlier_values = data_df[ (data_df[col_humidity] >= lower_bound_h) & \n",
    "                                 (data_df[col_humidity] <= upper_bound_h)][col_humidity]\n",
    "\n",
    "    median_h = non_outlier_values.median()\n",
    "\n",
    "    data_df[col_humidity] = data_df[col_humidity].apply(\n",
    "    lambda x: median_h if (x < lower_bound_h) or (x > upper_bound_h) else x)\n",
    "\n",
    "    print(f\"1.6 '{col_humidity}' ì´ìƒì¹˜ â†’ ì¤‘ì•™ê°’({median_h:.2f})ìœ¼ë¡œ ëŒ€ì²´ ì™„ë£Œ (shape: {data_df.shape})\")\n",
    "   \n",
    "    # T-1, T-2, T-3,,, ë§Œë“¤ê¸°\n",
    "\n",
    "    print(\"1.7 ì‹œê³„ì—´ ì¬ë°°ì—´ (T+N â†’ T-N í˜•íƒœë¡œ ì •ë ¬)\")\n",
    "    horizons = [1, 2, 3, 4]\n",
    "\n",
    "    # ìš°ë¦¬ê°€ ì»¤ë²„í•  ì›ë³¸ ì»¬ëŸ¼ íŒ¨í„´ë“¤\n",
    "    plan_sources = [\n",
    "        (\"T+{h}ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰\",        \"T-{h}_ì˜ˆì •\"),     \n",
    "        (\"T+{h}ì¼ ì˜ˆìƒ ìˆ˜ì£¼ëŸ‰\",        \"T-{h}_ì˜ˆìƒ\"),     \n",
    "        (\"ì‘ë…„ T+{h}ì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰\",   \"T-{h}_ì‘ë…„\"), \n",
    "        \n",
    "    ]\n",
    "\n",
    "    for h in horizons:\n",
    "        for src_tmpl, dst_tmpl in plan_sources:\n",
    "            src_col = src_tmpl.format(h=h)\n",
    "            dst_col = dst_tmpl.format(h=h)\n",
    "\n",
    "            if src_col in data_df.columns:\n",
    "                # hì¼ ì „ snapshotì„ ì˜¤ëŠ˜ rowì— ë¶™ì¸ë‹¤\n",
    "                data_df[dst_col] = data_df.groupby('Product_Number', group_keys=False)[src_col].shift(h)\n",
    "            # ì—†ìœ¼ë©´ ê·¸ëƒ¥ skip (ì»¬ëŸ¼ì´ ì‹¤ì œë¡œ ì—†ëŠ” ê²½ìš° ëŒ€ë¹„)\n",
    "\n",
    "    # 1.8 ìµœì¢…ì ìœ¼ë¡œ ê³µìœ /ì €ì¥í•  df_clean ì»¬ëŸ¼ ì„ íƒ\n",
    "    final_cols = [\n",
    "        'Product_Number',\n",
    "\n",
    "        # íƒ€ê¹ƒ ë° ê¸°ì¤€ì—´\n",
    "        'Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰',\n",
    "        'ì‘ë…„ Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰',\n",
    "        'Tì¼ ì˜ˆìƒ ìˆ˜ì£¼ëŸ‰',\n",
    "\n",
    "        # ì¬ë°°ì—´ëœ ê³„íš ìŠ¤ëƒ…ìƒ·ë“¤\n",
    "        'T-1_ì˜ˆì •', 'T-1_ì˜ˆìƒ', 'T-1_ì‘ë…„',\n",
    "        'T-2_ì˜ˆì •', 'T-2_ì˜ˆìƒ', 'T-2_ì‘ë…„',\n",
    "        'T-3_ì˜ˆì •', 'T-3_ì˜ˆìƒ', 'T-3_ì‘ë…„',\n",
    "        'T-4_ì˜ˆì •', 'T-4_ì˜ˆìƒ', 'T-4_ì‘ë…„',\n",
    "\n",
    "        # í™˜ê²½ ìš”ì¸\n",
    "        'Temperature', 'Humidity',\n",
    "\n",
    "        # ë‚ ì§œ/ì‹œê°„\n",
    "        'Date', 'Time',\n",
    "    ]\n",
    "\n",
    "    df_clean = data_df[final_cols].copy()\n",
    "\n",
    "    # 1.9 Dateë¥¼ pandas datetimeìœ¼ë¡œ í†µì¼í•´ì„œ ì €ì¥ (ë‚˜ì¤‘ì— merge/sort ì•ˆì •ì„± â†‘)\n",
    "    # ì§€ê¸ˆ Dateê°€ dtype=object (python date)ì¼ ê°€ëŠ¥ì„± â†’ pandas Timestampë¡œ ë°”ê¿”ì¤Œ\n",
    "    df_clean['Date'] = pd.to_datetime(df_clean['Date'], errors='coerce')\n",
    "\n",
    "\n",
    "    # Time ì»¬ëŸ¼ ì‚­ì œ\n",
    "    if 'Time' in df_clean.columns:\n",
    "        df_clean.drop(columns=['Time'], inplace=True)\n",
    "\n",
    "    # NaN ìˆëŠ” í–‰ ì œê±°í•˜ê³  ì‹¶ìœ¼ë©´ ì£¼ì„ ì œê±° í›„ ì‚¬ìš©\n",
    "    # df_clean = df_clean.dropna().reset_index(drop=True)\n",
    "\n",
    "    df_clean.to_csv(output_final_csv_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"1ë‹¨ê³„ ê³µí†µ ì „ì²˜ë¦¬ ì™„ë£Œ! (df_clean shape: {df_clean.shape})\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ğŸš¨ {e}\")\n",
    "    df_clean = None\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ 1ë‹¨ê³„ ë°ì´í„° ë¡œë“œ ë° ê³µí†µ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    df_clean = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c49e5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Product_Number', 'Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰', 'ì‘ë…„ Tì¼ ì˜ˆì • ìˆ˜ì£¼ëŸ‰', 'Tì¼ ì˜ˆìƒ ìˆ˜ì£¼ëŸ‰', 'T-1_ì˜ˆì •',\n",
       "       'T-1_ì˜ˆìƒ', 'T-1_ì‘ë…„', 'T-2_ì˜ˆì •', 'T-2_ì˜ˆìƒ', 'T-2_ì‘ë…„', 'T-3_ì˜ˆì •', 'T-3_ì˜ˆìƒ',\n",
       "       'T-3_ì‘ë…„', 'T-4_ì˜ˆì •', 'T-4_ì˜ˆìƒ', 'T-4_ì‘ë…„', 'Temperature', 'Humidity',\n",
       "       'Date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c21ae",
   "metadata": {},
   "source": [
    "### ----ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ Product_Number ë¼ë²¨ ì¸ì½”ë”© ë° ì¸ì½”ë”© íŒŒì¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "828857cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_product = LabelEncoder()\n",
    "df_clean['Product_Number'] = le_product.fit_transform(df_clean['Product_Number'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f52e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "mapping = dict(zip(le_product.classes_, le_product.transform(le_product.classes_)))\n",
    "mapping = {k: int(v) for k, v in mapping.items()}  # <-- í•µì‹¬\n",
    "\n",
    "with open('product_label_mapping.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(mapping, f, ensure_ascii=False, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SFO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
